{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/specM7/DSGP_Group_33_Brain_Tumor_Predictor/blob/Meningioma_Adrian_2425482/Meningioma_Adrian_2425482.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVt_hc2odyi"
      },
      "source": [
        "# ğŸ§  AI-Powered Brain Tumor Predictor for Meningioma(Adrian)\n",
        "\n",
        "\n",
        "## Project Goal\n",
        "Build a Convolutional Neural Network (CNN) to classify brain MRI images into 4 tumor categories.\n",
        "\n",
        "## Technologies Used\n",
        "- **TensorFlow/Keras** - Deep Learning Framework\n",
        "- **OpenCV** - Image Processing\n",
        "- **NumPy** - Numerical Computing\n",
        "\n",
        "\n",
        "## Model Specifications\n",
        "- **Input**: 224x224 grayscale MRI images\n",
        "- **Architecture**: Custom CNN with 3 convolutional blocks\n",
        "- **Output**: 4-class classification (tumor types)\n",
        "- **Training**: 25 epochs with validation split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Objectives\n",
        "1. Build a robust CNN model for brain tumor classification\n",
        "2. Achieve >90% accuracy on test data\n",
        "3. Provide interpretable results with visualization"
      ],
      "metadata": {
        "id": "Fw22pub6QpDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kiz1o1995nsU"
      },
      "outputs": [],
      "source": [
        "import os, glob, cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Extract Dataset\n",
        "Unzips your file and shows folder structure."
      ],
      "metadata": {
        "id": "6kM1GvNebcBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2ï¸ Dataset Preparation\n",
        "\n",
        "###  Upload Dataset\n",
        "Upload your `DataSet.zip` file containing:\n",
        "```\n",
        "DataSet/\n",
        "â”œâ”€â”€ Training/\n",
        "â”‚   â”œâ”€â”€ glioma/\n",
        "â”‚   â”œâ”€â”€ meningioma/\n",
        "â”‚   â”œâ”€â”€ notumor/\n",
        "â”‚   â””â”€â”€ pituitary/\n",
        "â””â”€â”€ Testing/\n",
        "    â”œâ”€â”€ glioma/\n",
        "    â”œâ”€â”€ meningioma/\n",
        "    â”œâ”€â”€ notumor/\n",
        "    â””â”€â”€ pituitary/\n",
        "```\n",
        "\n",
        "**Click the upload button below to select your dataset ZIP file.**"
      ],
      "metadata": {
        "id": "vegHX-3fQ674"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVO1aF3Q5pY_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()        # PICK the real DataSet.zip from your PC\n",
        "\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", zip_name)\n",
        "\n",
        "# Unzip into /content/DataSet_raw\n",
        "!rm -rf /content/DataSet_raw\n",
        "!mkdir -p /content/DataSet_raw\n",
        "!unzip -q \"$zip_name\" -d /content/DataSet_raw\n",
        "\n",
        "print(\"\\nTop level under /content/DataSet_raw:\")\n",
        "!ls /content/DataSet_raw\n",
        "\n",
        "print(\"\\nAny 'Training' folders:\")\n",
        "!find /content/DataSet_raw -maxdepth 5 -type d -iname \"Training\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Set Paths\n",
        "Look at previous output, find your Training folder path, and paste it in next cell.\n",
        "\n",
        "Example: `/content/DataSet_raw/DataSet/Training`"
      ],
      "metadata": {
        "id": "gPuXo1rG_L5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBnG68i_6ulT"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_path = \"/content/DataSet_raw/DataSet/Training\"   # example, edit to your real one\n",
        "\n",
        "raw_root = os.path.dirname(training_path)\n",
        "print(\"training_path:\", training_path)\n",
        "print(\"raw_root:\", raw_root)\n",
        "print(\"RAW training folders:\", os.listdir(training_path))\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = training_path\n",
        "test_dir  = os.path.join(raw_root, \"Testing\")\n",
        "print(\"train_dir:\", train_dir)\n",
        "print(\"test_dir:\", test_dir)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#   CLEAN DATASET CREATION â€“ NO DUPLICATES\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    color_mode='grayscale',\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_ds = val_test_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    color_mode='grayscale',\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_ds = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    color_mode='grayscale',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"Classes / indices:\", train_ds.class_indices)\n",
        "print(\"Number of training batches:\", len(train_ds))\n",
        "print(\"Number of validation batches:\", len(val_ds))\n",
        "print(\"Number of test batches:\", len(test_ds))\n",
        "\n"
      ],
      "metadata": {
        "id": "KK4Fuc0nWx4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6ï¸ Model Evaluation\n",
        "\n",
        "###  Testing on Unseen Data\n",
        "\n",
        "Now we'll evaluate the model on completely unseen test data to measure real-world performance.\n",
        "\n",
        "**Test Set:** Independent images never seen during training"
      ],
      "metadata": {
        "id": "jxU0CZsI_dGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Meningioma class ID:\", train_ds.class_indices['meningioma'])"
      ],
      "metadata": {
        "id": "734O3aoPXhcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXgzQ7Du6yWZ"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Input(shape=(*img_size, 1)),\n",
        "    layers.Rescaling(1./255),\n",
        "\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.Recall(class_id=train_ds.class_indices['meningioma'], name='meningioma_recall'),\n",
        "        tf.keras.metrics.Precision(class_id=train_ds.class_indices['meningioma'], name='meningioma_precision')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Optional but strongly recommended: class weights\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_ds.classes),\n",
        "    y=train_ds.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=6,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,               # more epochs is ok now because of early stopping\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Unpack all four metrics returned by model.evaluate\n",
        "test_loss, test_acc, test_meningioma_recall, test_meningioma_precision = model.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "print(\"Test Meningioma Recall:\", test_meningioma_recall)\n",
        "print(\"Test Meningioma Precision:\", test_meningioma_precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Save & Export Model\n",
        "\n",
        "###  Saving Trained Model\n",
        "\n",
        "The model will be saved in HDF5 format (.h5) which includes:\n",
        "- âœ… Model architecture\n",
        "- âœ… Trained weights\n",
        "- âœ… Optimizer state\n",
        "- âœ… Training configuration\n",
        "\n",
        "**File:** `brain_tumor_mri_model.h5`"
      ],
      "metadata": {
        "id": "AVvnGfJglztt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV6fdCyZygBl"
      },
      "outputs": [],
      "source": [
        "model.save(\"brain_tumor_mri_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqt8OJQP0Xq8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"brain_tumor_mri_model.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Wsg3e9v2/T+F+Ov8Ob+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}