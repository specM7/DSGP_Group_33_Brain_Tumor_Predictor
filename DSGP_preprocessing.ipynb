{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/specM7/DSGP_Group_33_Brain_Tumor_Predictor/blob/Pituitary-Adenomas-Malindu-2425440/DSGP_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0lPNI7FoKjc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "aloPCB6JSXu0",
        "outputId": "d8d55f23-5a9c-4d0f-d1cb-ef0fa236899b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for training and testing data\n",
        "train_dir = '/content/drive/MyDrive/Training'\n",
        "# Define image size for VGG16\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "\n",
        "# Load and shuffle the train data\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "for label in os.listdir(train_dir):\n",
        "    for image in os.listdir(os.path.join(train_dir, label)):\n",
        "        train_paths.append(os.path.join(train_dir, label, image))\n",
        "        train_labels.append(label)\n",
        "\n",
        "train_paths, train_labels = shuffle(train_paths, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BYWEMnTDpchc",
        "outputId": "3f5e0e12-dc0b-45fa-ec40-ba8150f16f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/Training/Tr-pi_1403.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4233591934.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/Training/Tr-pi_1403.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Select random indices for 10 images\n",
        "random_indices = random.sample(range(len(train_paths)), 10)\n",
        "\n",
        "# Create a figure to display images in 2 rows\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Load image\n",
        "    img_path = train_paths[idx]\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((224, 224))  # Resize to consistent size\n",
        "\n",
        "    # Display image\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].axis('off')  # Hide axis\n",
        "    # Display class label in the second row\n",
        "    axes[i].set_title(f\"Label: {train_labels[idx]}\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LPxXR78dtIXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Augmentation function\n",
        "def augment_image(image):\n",
        "    image = Image.fromarray(np.uint8(image))\n",
        "    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8, 1.2))  # Random brightness\n",
        "    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8, 1.2))  # Random contrast\n",
        "    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Load images and apply augmentation\n",
        "def open_images(paths):\n",
        "    images = []\n",
        "    IMAGE_SIZE = 244\n",
        "    for path in paths:\n",
        "        image = load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "        image = augment_image(image)\n",
        "        images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "# Encoding labels (convert label names to integers)\n",
        "def encode_label(labels):\n",
        "    unique_labels = os.listdir(train_dir)  # Ensure unique labels are determined\n",
        "    encoded = [unique_labels.index(label) for label in labels]\n",
        "    return np.array(encoded)\n",
        "\n",
        "# Data generator for batching\n",
        "def datagen(paths, labels, batch_size=12, epochs=1):\n",
        "    for _ in range(epochs):\n",
        "        for i in range(0, len(paths), batch_size):\n",
        "            batch_paths = paths[i:i + batch_size]\n",
        "            batch_images = open_images(batch_paths)  # Open and augment images\n",
        "            batch_labels = labels[i:i + batch_size]\n",
        "            batch_labels = encode_label(batch_labels)  # Encode labels\n",
        "            yield batch_images, batch_labels  # Yield the batch"
      ],
      "metadata": {
        "id": "Y_Vmp2Cet1pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VGG16 model without top layers for feature extraction\n",
        "def create_vgg16_feature_extractor():\n",
        "    IMAGE_SIZE = 244\n",
        "    vgg_base = VGG16(weights='imagenet',\n",
        "                     include_top=False,\n",
        "                     input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "\n",
        "    # Freeze all layers\n",
        "    for layer in vgg_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return vgg_base\n",
        "\n",
        "# Feature extraction function\n",
        "def extract_features(paths, labels, vgg_model, batch_size=32):\n",
        "    all_features = []\n",
        "    all_encoded_labels = []\n",
        "\n",
        "    # Encode all labels first\n",
        "    encoded_labels = encode_label(labels)\n",
        "\n",
        "    # Process in batches to avoid memory issues\n",
        "    for i in range(0, len(paths), batch_size):\n",
        "        batch_paths = paths[i:i + batch_size]\n",
        "        batch_labels = encoded_labels[i:i + batch_size]\n",
        "\n",
        "        # Load and preprocess images\n",
        "        batch_images = open_images(batch_paths)\n",
        "\n",
        "        # Extract features using VGG16\n",
        "        features = vgg_model.predict(batch_images, verbose=0)\n",
        "        features_flat = features.reshape(features.shape[0], -1)\n",
        "\n",
        "        all_features.append(features_flat)\n",
        "        all_encoded_labels.extend(batch_labels)\n",
        "\n",
        "    # Combine all features\n",
        "    all_features = np.vstack(all_features)\n",
        "    all_encoded_labels = np.array(all_encoded_labels)\n",
        "\n",
        "    return all_features, all_encoded_labels"
      ],
      "metadata": {
        "id": "kzUHL7PLuXzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the hybrid model\n",
        "def create_hybrid_model():\n",
        "    # Create VGG16 feature extractor\n",
        "    vgg_model = create_vgg16_feature_extractor()\n",
        "\n",
        "    # Extract features from training data\n",
        "    train_features, train_encoded_labels = extract_features(train_paths, train_labels, vgg_model)\n",
        "\n",
        "    print(f\"Training features shape: {train_features.shape}\")\n",
        "    print(f\"Training labels shape: {train_encoded_labels.shape}\")\n",
        "\n",
        "    # Create and train Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        random_state=42,\n",
        "        n_jobs=-1  # Use all available cores\n",
        "    )\n",
        "\n",
        "    rf_classifier.fit(train_features, train_encoded_labels)\n",
        "\n",
        "    return vgg_model, rf_classifier\n",
        "\n",
        "# ====Using VGG and sequential models : 1st prototype====\n",
        "#     # Model architecture\n",
        "# IMAGE_SIZE = 128  # Image size (adjust based on your requirements)\n",
        "# base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# # Freeze all layers of the VGG16 base model\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Set the last few layers of the VGG16 base model to be trainable\n",
        "# base_model.layers[-2].trainable = True\n",
        "# base_model.layers[-3].trainable = True\n",
        "# base_model.layers[-4].trainable = True\n",
        "\n",
        "# # Build the final model\n",
        "# model = Sequential()\n",
        "# model.add(Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))  # Input layer\n",
        "# model.add(base_model)  # Add VGG16 base model\n",
        "# model.add(Flatten())  # Flatten the output of the base model\n",
        "# model.add(Dropout(0.3))  # Dropout layer for regularization\n",
        "# model.add(Dense(128, activation='relu'))  # Dense layer with ReLU activation\n",
        "# model.add(Dropout(0.2))  # Dropout layer for regularization\n",
        "# model.add(Dense(len(os.listdir(train_dir)), activation='softmax'))  # Output layer with softmax activation\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "# # Parameters\n",
        "# batch_size = 20\n",
        "# steps = int(len(train_paths) / batch_size)  # Steps per epoch\n",
        "# epochs = 5\n",
        "\n",
        "# # Train the model\n",
        "# history = model.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n",
        "#                     epochs=epochs, steps_per_epoch=steps)"
      ],
      "metadata": {
        "id": "0Yk-EZMDJ1iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions\n",
        "def predict_images(paths, vgg_model, rf_classifier, batch_size=32):\n",
        "    all_predictions = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    # Get unique labels for decoding\n",
        "    unique_labels = os.listdir(train_dir)\n",
        "\n",
        "    for i in range(0, len(paths), batch_size):\n",
        "        batch_paths = paths[i:i + batch_size]\n",
        "\n",
        "        # Load and preprocess images\n",
        "        batch_images = open_images(batch_paths)\n",
        "\n",
        "        # Extract features using VGG16\n",
        "        features = vgg_model.predict(batch_images, verbose=0)\n",
        "        features_flat = features.reshape(features.shape[0], -1)\n",
        "\n",
        "        # Make predictions\n",
        "        batch_predictions = rf_classifier.predict(features_flat)\n",
        "        batch_probabilities = rf_classifier.predict_proba(features_flat)\n",
        "\n",
        "        # Decode predictions back to label names\n",
        "        decoded_predictions = [unique_labels[pred] for pred in batch_predictions]\n",
        "\n",
        "        all_predictions.extend(decoded_predictions)\n",
        "        all_probabilities.append(batch_probabilities)\n",
        "\n",
        "    all_probabilities = np.vstack(all_probabilities)\n",
        "    return all_predictions, all_probabilities\n"
      ],
      "metadata": {
        "id": "rS7sfCdfJ4yG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}