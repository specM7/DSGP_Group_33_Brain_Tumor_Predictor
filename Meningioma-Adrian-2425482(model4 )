{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14844279,"sourceType":"datasetVersion","datasetId":9494204}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Meningioma MRI Detection Model (Binary Classifier)\n\n**Complete Kaggle Notebook** â€“ Ready to copy-paste and run.\n\nThis notebook trains a **binary ResNet50** (meningioma vs. non-meningioma) using transfer learning, evaluates it thoroughly, adds **Grad-CAM explainability**, and includes a reusable inference function for new MRIs.\n\n---\n\n## 1. Install Dependencies\n\n```python\n!pip install grad-cam -q","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom torchvision import datasets, transforms, models\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Full training dataset (no transform yet)\nfull_train_dataset = datasets.ImageFolder(\n    root='/kaggle/input/meningioma-dataset/Training'\n)\n\nprint(f\"Classes: {full_train_dataset.classes}\")\nprint(f\"Total training images: {len(full_train_dataset)}\")\n\n# 80/20 train/val split\ntrain_size = int(0.8 * len(full_train_dataset))\nval_size = len(full_train_dataset) - train_size\n\nindices = list(range(len(full_train_dataset)))\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\ntrain_indices = indices[:train_size]\nval_indices = indices[train_size:]\n\n# Custom wrapper to apply different transforms\nclass TransformedSubset(torch.utils.data.Dataset):\n    def __init__(self, dataset, indices, transform=None):\n        self.dataset = dataset\n        self.indices = indices\n        self.transform = transform\n    \n    def __getitem__(self, idx):\n        img, label = self.dataset[self.indices[idx]]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n    \n    def __len__(self):\n        return len(self.indices)\n\ntrain_dataset = TransformedSubset(full_train_dataset, train_indices, train_transform)\nval_dataset   = TransformedSubset(full_train_dataset, val_indices,   val_transform)\n\n# Test dataset\ntest_dataset = datasets.ImageFolder(\n    root='/kaggle/input/meningioma-dataset/Testing',\n    transform=val_transform\n)\n\nprint(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}