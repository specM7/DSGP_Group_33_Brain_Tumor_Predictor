{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14715912,"sourceType":"datasetVersion","datasetId":9402269},{"sourceId":741606,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":565838,"modelId":578275}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nprint(\"TensorFlow:\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:39.521408Z","iopub.execute_input":"2026-02-09T15:08:39.521596Z","iopub.status.idle":"2026-02-09T15:08:53.649635Z","shell.execute_reply.started":"2026-02-09T15:08:39.521576Z","shell.execute_reply":"2026-02-09T15:08:53.648949Z"}},"outputs":[{"name":"stderr","text":"2026-02-09 15:08:41.335195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770649721.509079      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770649721.568660      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770649722.002521      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770649722.002560      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770649722.002563      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770649722.002565      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow: 2.19.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/input/dsgp-dataset-zip/DataSet\"\nTRAIN_DIR = os.path.join(DATA_ROOT, \"/kaggle/input/dsgp-dataset-zip/DataSet/Training\")\nIMG_SIZE = 224","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:53.651343Z","iopub.execute_input":"2026-02-09T15:08:53.651803Z","iopub.status.idle":"2026-02-09T15:08:53.655632Z","shell.execute_reply.started":"2026-02-09T15:08:53.651777Z","shell.execute_reply":"2026-02-09T15:08:53.654749Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"clf_model = tf.keras.models.load_model(\"/kaggle/input/tumor-type-classification/tfjs/default/1/brain_tumor_mri_model (1).h5\")\nclf_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:53.657072Z","iopub.execute_input":"2026-02-09T15:08:53.657500Z","iopub.status.idle":"2026-02-09T15:08:56.899368Z","shell.execute_reply.started":"2026-02-09T15:08:53.657469Z","shell.execute_reply":"2026-02-09T15:08:56.898811Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1770649734.349364      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15511 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nWARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m25,690,624\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,624</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,084,486\u001b[0m (99.50 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,084,486</span> (99.50 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,082,500\u001b[0m (99.50 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,082,500</span> (99.50 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def load_images(folder):\n    images = []\n    filenames = []\n\n    for file in os.listdir(folder):\n        file_path = os.path.join(folder, file)\n\n        # Skip directories\n        if not os.path.isfile(file_path):\n            continue\n\n        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n\n        # Skip unreadable / non-image files\n        if img is None:\n            print(\"Skipping file:\", file)\n            continue\n\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img / 255.0\n\n        images.append(img)\n        filenames.append(file)\n\n    return np.array(images), filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.900197Z","iopub.execute_input":"2026-02-09T15:08:56.900476Z","iopub.status.idle":"2026-02-09T15:08:56.905242Z","shell.execute_reply.started":"2026-02-09T15:08:56.900444Z","shell.execute_reply":"2026-02-09T15:08:56.904673Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"images, filenames = load_images(TRAIN_DIR)\nimages = images[..., np.newaxis]\n\nprint(\"Loaded images:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.906126Z","iopub.execute_input":"2026-02-09T15:08:56.906398Z","iopub.status.idle":"2026-02-09T15:08:56.926524Z","shell.execute_reply.started":"2026-02-09T15:08:56.906375Z","shell.execute_reply":"2026-02-09T15:08:56.925947Z"}},"outputs":[{"name":"stdout","text":"Loaded images: (0, 1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def grad_cam(model, img_array, class_index, layer_name):\n    grad_model = tf.keras.models.Model(\n        [model.inputs],\n        [model.get_layer(layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.927264Z","iopub.execute_input":"2026-02-09T15:08:56.927532Z","iopub.status.idle":"2026-02-09T15:08:56.932833Z","shell.execute_reply.started":"2026-02-09T15:08:56.927512Z","shell.execute_reply":"2026-02-09T15:08:56.932096Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def grad_cam(model, img_array, class_index, layer_name):\n    grad_model = tf.keras.models.Model(\n        [model.inputs],\n        [model.get_layer(layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    conv_outputs = conv_outputs[0]\n\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.935101Z","iopub.execute_input":"2026-02-09T15:08:56.935676Z","iopub.status.idle":"2026-02-09T15:08:56.943223Z","shell.execute_reply.started":"2026-02-09T15:08:56.935654Z","shell.execute_reply":"2026-02-09T15:08:56.942632Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"MENINGIOMA_ID = 1\nprint(\"Meningioma class ID:\", MENINGIOMA_ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.944053Z","iopub.execute_input":"2026-02-09T15:08:56.944369Z","iopub.status.idle":"2026-02-09T15:08:56.956652Z","shell.execute_reply.started":"2026-02-09T15:08:56.944310Z","shell.execute_reply":"2026-02-09T15:08:56.955996Z"}},"outputs":[{"name":"stdout","text":"Meningioma class ID: 1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(clf_model.output_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.957423Z","iopub.execute_input":"2026-02-09T15:08:56.957728Z","iopub.status.idle":"2026-02-09T15:08:56.967008Z","shell.execute_reply.started":"2026-02-09T15:08:56.957697Z","shell.execute_reply":"2026-02-09T15:08:56.966449Z"}},"outputs":[{"name":"stdout","text":"(None, 4)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for layer in clf_model.layers:\n    if \"conv\" in layer.name:\n        print(layer.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.967692Z","iopub.execute_input":"2026-02-09T15:08:56.967941Z","iopub.status.idle":"2026-02-09T15:08:56.977189Z","shell.execute_reply.started":"2026-02-09T15:08:56.967922Z","shell.execute_reply":"2026-02-09T15:08:56.976550Z"}},"outputs":[{"name":"stdout","text":"conv2d\nconv2d_1\nconv2d_2\nconv2d_3\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"LAYER_NAME = \"conv2d_3\"   # or whatever the last one is","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.978051Z","iopub.execute_input":"2026-02-09T15:08:56.978470Z","iopub.status.idle":"2026-02-09T15:08:56.987124Z","shell.execute_reply.started":"2026-02-09T15:08:56.978442Z","shell.execute_reply":"2026-02-09T15:08:56.986379Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"masks = []\n\nfor img in images:\n    input_img = np.expand_dims(img, axis=0).astype(np.float32)\n\n    heatmap = grad_cam(\n        model=clf_model,\n        img_array=input_img,\n        class_index=MENINGIOMA_ID,\n        layer_name=LAYER_NAME\n    )\n\n    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n    mask = (heatmap > 0.4).astype(np.uint8)  # binary mask\n    masks.append(mask)\n\nmasks = np.array(masks)[..., np.newaxis]\nprint(\"Masks shape:\", masks.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.988012Z","iopub.execute_input":"2026-02-09T15:08:56.988286Z","iopub.status.idle":"2026-02-09T15:08:56.997804Z","shell.execute_reply.started":"2026-02-09T15:08:56.988266Z","shell.execute_reply":"2026-02-09T15:08:56.997174Z"}},"outputs":[{"name":"stdout","text":"Masks shape: (0, 1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(\"Images shape:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:56.998577Z","iopub.execute_input":"2026-02-09T15:08:56.998814Z","iopub.status.idle":"2026-02-09T15:08:57.009071Z","shell.execute_reply.started":"2026-02-09T15:08:56.998784Z","shell.execute_reply":"2026-02-09T15:08:57.008525Z"}},"outputs":[{"name":"stdout","text":"Images shape: (0, 1)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"TRAIN_DIR =\", TRAIN_DIR)\nprint(\"Contents:\", os.listdir(TRAIN_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:57.009928Z","iopub.execute_input":"2026-02-09T15:08:57.010213Z","iopub.status.idle":"2026-02-09T15:08:57.019762Z","shell.execute_reply.started":"2026-02-09T15:08:57.010185Z","shell.execute_reply":"2026-02-09T15:08:57.019120Z"}},"outputs":[{"name":"stdout","text":"TRAIN_DIR = /kaggle/input/dsgp-dataset-zip/DataSet/Training\nContents: ['pituitary', 'notumor', 'meningioma', 'glioma']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"MENINGIOMA_DIR = os.path.join(TRAIN_DIR, \"meningioma\")\n\nprint(\"MENINGIOMA_DIR exists:\", os.path.isdir(MENINGIOMA_DIR))\nprint(\"Number of files:\", len(os.listdir(MENINGIOMA_DIR)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:57.020605Z","iopub.execute_input":"2026-02-09T15:08:57.020836Z","iopub.status.idle":"2026-02-09T15:08:57.044749Z","shell.execute_reply.started":"2026-02-09T15:08:57.020817Z","shell.execute_reply":"2026-02-09T15:08:57.044195Z"}},"outputs":[{"name":"stdout","text":"MENINGIOMA_DIR exists: True\nNumber of files: 1339\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"images, filenames = load_images(MENINGIOMA_DIR)\nimages = images[..., np.newaxis]\n\nprint(\"Loaded images shape:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:08:57.045494Z","iopub.execute_input":"2026-02-09T15:08:57.045781Z","iopub.status.idle":"2026-02-09T15:09:09.461311Z","shell.execute_reply.started":"2026-02-09T15:08:57.045762Z","shell.execute_reply":"2026-02-09T15:09:09.460661Z"}},"outputs":[{"name":"stdout","text":"Loaded images shape: (1339, 224, 224, 1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"IMG_SIZE = 224\n\ndef load_images(folder):\n    images = []\n    filenames = []\n\n    for file in os.listdir(folder):\n        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n            continue\n\n        path = os.path.join(folder, file)\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n        if img is None:\n            print(\"⚠️ Failed to load:\", file)\n            continue\n\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img.astype(np.float32) / 255.0\n\n        images.append(img)\n        filenames.append(file)\n\n    return np.array(images), filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:09.462135Z","iopub.execute_input":"2026-02-09T15:09:09.462436Z","iopub.status.idle":"2026-02-09T15:09:09.468087Z","shell.execute_reply.started":"2026-02-09T15:09:09.462412Z","shell.execute_reply":"2026-02-09T15:09:09.467438Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Force model to build graph\n_ = clf_model.predict(images[:1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:09.468961Z","iopub.execute_input":"2026-02-09T15:09:09.469234Z","iopub.status.idle":"2026-02-09T15:09:11.401001Z","shell.execute_reply.started":"2026-02-09T15:09:09.469204Z","shell.execute_reply":"2026-02-09T15:09:11.400262Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1770649749.913676     122 service.cc:152] XLA service 0x78740800d360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1770649749.913707     122 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1770649750.068154     122 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1770649751.376415     122 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\ndef grad_cam(model, img_array, class_index, layer_name):\n    conv_layer = model.get_layer(layer_name)\n\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[conv_layer.output, model.output]  # model.output (NOT model.outputs)\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_index]  # now predictions is a tensor\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n\n    heatmap = tf.maximum(heatmap, 0)\n    heatmap /= tf.reduce_max(heatmap) + 1e-8\n\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:11.401974Z","iopub.execute_input":"2026-02-09T15:09:11.402379Z","iopub.status.idle":"2026-02-09T15:09:11.409482Z","shell.execute_reply.started":"2026-02-09T15:09:11.402339Z","shell.execute_reply":"2026-02-09T15:09:11.408602Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:11.410535Z","iopub.execute_input":"2026-02-09T15:09:11.410851Z","iopub.status.idle":"2026-02-09T15:09:11.421766Z","shell.execute_reply.started":"2026-02-09T15:09:11.410823Z","shell.execute_reply":"2026-02-09T15:09:11.420965Z"}},"outputs":[{"name":"stdout","text":"(1339, 224, 224, 1)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import os, cv2\nimport numpy as np\n\nIMG_SIZE = 224\nMENINGIOMA_DIR = os.path.join(TRAIN_DIR, \"meningioma\")\n\ndef load_images(folder):\n    images = []\n    filenames = []\n\n    for file in os.listdir(folder):\n        path = os.path.join(folder, file)\n\n        if not file.lower().endswith(('.png', '.jpg', '.jpeg')):\n            continue\n\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        if img is None:\n            continue\n\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img / 255.0\n\n        images.append(img)\n        filenames.append(file)\n\n    return np.array(images), filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:11.422957Z","iopub.execute_input":"2026-02-09T15:09:11.423420Z","iopub.status.idle":"2026-02-09T15:09:11.434842Z","shell.execute_reply.started":"2026-02-09T15:09:11.423369Z","shell.execute_reply":"2026-02-09T15:09:11.434085Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"images, filenames = load_images(MENINGIOMA_DIR)\nimages = images[..., np.newaxis]\n\nprint(\"Images shape:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:11.437865Z","iopub.execute_input":"2026-02-09T15:09:11.438181Z","iopub.status.idle":"2026-02-09T15:09:15.565043Z","shell.execute_reply.started":"2026-02-09T15:09:11.438153Z","shell.execute_reply":"2026-02-09T15:09:15.564389Z"}},"outputs":[{"name":"stdout","text":"Images shape: (1339, 224, 224, 1)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Force model graph to build\n_ = clf_model.predict(images[:1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:15.565763Z","iopub.execute_input":"2026-02-09T15:09:15.565978Z","iopub.status.idle":"2026-02-09T15:09:15.632273Z","shell.execute_reply.started":"2026-02-09T15:09:15.565959Z","shell.execute_reply":"2026-02-09T15:09:15.631742Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import tensorflow as tf\n\ndef grad_cam(model, img_array, class_index, layer_name):\n    conv_layer = model.get_layer(layer_name)\n\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[conv_layer.output, model.outputs]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, class_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n\n    heatmap = tf.maximum(heatmap, 0)\n    heatmap /= tf.reduce_max(heatmap) + 1e-8\n\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:15.633021Z","iopub.execute_input":"2026-02-09T15:09:15.633287Z","iopub.status.idle":"2026-02-09T15:09:15.638727Z","shell.execute_reply.started":"2026-02-09T15:09:15.633256Z","shell.execute_reply":"2026-02-09T15:09:15.637904Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MENINGIOMA_ID = clf_model.predict(images[:1]).argmax()\nprint(\"Using predicted class ID:\", MENINGIOMA_ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:15.639532Z","iopub.execute_input":"2026-02-09T15:09:15.639851Z","iopub.status.idle":"2026-02-09T15:09:15.710137Z","shell.execute_reply.started":"2026-02-09T15:09:15.639830Z","shell.execute_reply":"2026-02-09T15:09:15.709588Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\nUsing predicted class ID: 1\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print(\"Images shape:\", images.shape)\nprint(\"Number of images:\", len(images))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:15.710901Z","iopub.execute_input":"2026-02-09T15:09:15.711185Z","iopub.status.idle":"2026-02-09T15:09:15.715132Z","shell.execute_reply.started":"2026-02-09T15:09:15.711162Z","shell.execute_reply":"2026-02-09T15:09:15.714375Z"}},"outputs":[{"name":"stdout","text":"Images shape: (1339, 224, 224, 1)\nNumber of images: 1339\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def grad_cam(model, img_array, class_index, layer_name):\n    conv_layer = model.get_layer(layer_name)\n\n    # Use model.output (singular) to get the tensor, not the list\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[conv_layer.output, model.output] \n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        # Now 'predictions' is a Tensor, so this slicing works:\n        loss = predictions[:, class_index]\n\n    # Calculate gradients of the loss w.r.t. the conv layer output\n    grads = tape.gradient(loss, conv_outputs)\n    \n    # Mean of gradients across height/width (Global Average Pooling)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # Weight the channels of the conv output by the pooled gradients\n    conv_outputs = conv_outputs[0]\n    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n\n    # ReLU and Normalize\n    heatmap = tf.maximum(heatmap, 0)\n    heatmap /= (tf.reduce_max(heatmap) + 1e-8)\n\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:09:15.715905Z","iopub.execute_input":"2026-02-09T15:09:15.716187Z","iopub.status.idle":"2026-02-09T15:09:15.726224Z","shell.execute_reply.started":"2026-02-09T15:09:15.716159Z","shell.execute_reply":"2026-02-09T15:09:15.725566Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# These should already be set earlier in your notebook\nIMG_SIZE = 224\nLAYER_NAME = \"conv2d_3\"          # ← last/biggest conv layer — check your model.summary()\nMENINGIOMA_ID = 1                # or whatever index meningioma has in your 4 classes\n\n# Assuming you already have:\n# test_images     → shape (N, 224, 224, 1) or (N, 224, 224, 3)\n# test_labels     → shape (N,)     integers 0–3\n# CLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:15:07.846378Z","iopub.execute_input":"2026-02-09T15:15:07.847150Z","iopub.status.idle":"2026-02-09T15:15:07.850797Z","shell.execute_reply.started":"2026-02-09T15:15:07.847122Z","shell.execute_reply":"2026-02-09T15:15:07.850070Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ────────────────────────────────────────────────\n# 1. Define paths & classes (should already exist, but make sure)\n# ────────────────────────────────────────────────\n\nimport os\nimport numpy as np\nimport cv2\n\nDATA_ROOT = \"/kaggle/input/dsgp-dataset-zip/DataSet\"\nTEST_DIR = os.path.join(DATA_ROOT, \"Testing\")\n\nCLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']\nCLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASSES)}\n\nIMG_SIZE = 224\n\n# ────────────────────────────────────────────────\n# 2. Reuse or slightly improve your load_images function\n# ────────────────────────────────────────────────\n\ndef load_images_from_folder(folder):\n    images = []\n    filenames = []\n    \n    for file in os.listdir(folder):\n        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n            continue\n            \n        path = os.path.join(folder, file)\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        \n        if img is None:\n            continue\n            \n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img.astype(np.float32) / 255.0\n        \n        images.append(img)\n        filenames.append(file)\n    \n    if not images:\n        print(f\"Warning: No images loaded from {folder}\")\n        return np.array([]), []\n        \n    return np.array(images), filenames\n\n\n# ────────────────────────────────────────────────\n# 3. Load ALL test images + labels\n# ────────────────────────────────────────────────\n\ntest_images_list = []\ntest_labels_list = []\ntest_filenames = []\n\nfor class_name in CLASSES:\n    class_folder = os.path.join(TEST_DIR, class_name)\n    if not os.path.isdir(class_folder):\n        print(f\"Folder not found: {class_folder}\")\n        continue\n        \n    imgs, fnames = load_images_from_folder(class_folder)\n    if len(imgs) == 0:\n        continue\n        \n    test_images_list.append(imgs)\n    test_labels_list.append(np.full(len(imgs), CLASS_TO_IDX[class_name]))\n    test_filenames.extend(fnames)\n\n# Combine\nif test_images_list:\n    test_images = np.concatenate(test_images_list, axis=0)[..., np.newaxis]   # (N, 224, 224, 1)\n    test_labels = np.concatenate(test_labels_list)\n    print(f\"Test set loaded → {len(test_images)} images, shape: {test_images.shape}\")\nelse:\n    print(\"ERROR: No test images were loaded at all!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:15:43.741986Z","iopub.execute_input":"2026-02-09T15:15:43.742693Z","iopub.status.idle":"2026-02-09T15:16:03.296375Z","shell.execute_reply.started":"2026-02-09T15:15:43.742665Z","shell.execute_reply":"2026-02-09T15:16:03.295603Z"}},"outputs":[{"name":"stdout","text":"Test set loaded → 1826 images, shape: (1826, 224, 224, 1)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ────────────────────────────────────────────────\n# 4. Now it's safe to do dummy prediction\n# ────────────────────────────────────────────────\n\n_ = clf_model.predict(test_images[:1], verbose=0)\nprint(\"Model graph built successfully (no more 'never called' errors)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:16:09.503931Z","iopub.execute_input":"2026-02-09T15:16:09.504215Z","iopub.status.idle":"2026-02-09T15:16:09.571502Z","shell.execute_reply.started":"2026-02-09T15:16:09.504190Z","shell.execute_reply":"2026-02-09T15:16:09.570896Z"}},"outputs":[{"name":"stdout","text":"Model graph built successfully (no more 'never called' errors)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"print(\"Does TEST_DIR exist?\", os.path.isdir(TEST_DIR))\nprint(\"Subfolders:\", os.listdir(TEST_DIR) if os.path.isdir(TEST_DIR) else \"— folder missing —\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:16:15.797685Z","iopub.execute_input":"2026-02-09T15:16:15.797972Z","iopub.status.idle":"2026-02-09T15:16:15.809270Z","shell.execute_reply.started":"2026-02-09T15:16:15.797948Z","shell.execute_reply":"2026-02-09T15:16:15.808710Z"}},"outputs":[{"name":"stdout","text":"Does TEST_DIR exist? True\nSubfolders: ['pituitary', 'notumor', 'meningioma', 'glioma']\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(\"Variable 'test_images' exists?\", 'test_images' in globals())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:16:21.459960Z","iopub.execute_input":"2026-02-09T15:16:21.460255Z","iopub.status.idle":"2026-02-09T15:16:21.464506Z","shell.execute_reply.started":"2026-02-09T15:16:21.460231Z","shell.execute_reply":"2026-02-09T15:16:21.463797Z"}},"outputs":[{"name":"stdout","text":"Variable 'test_images' exists? True\n","output_type":"stream"}],"execution_count":34}]}